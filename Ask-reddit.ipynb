{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25YJuFLwNdMQ"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "V0X-3OhuaG_r"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.naive_bayes as naive_bayes\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sklearn.svm as svm \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "import string\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DLqoMTAenuMv",
    "outputId": "d1b141d6-a3e8-4154-b636-44096ace681d"
   },
   "outputs": [],
   "source": [
    "#nltk.download('stopwords') \n",
    "#nltk.download('wordnet') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BM4u8_wgNiQl"
   },
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TNYZ87XncCIB"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"C:/Users/saira/Desktop/B-Tech/projects/AskReddit-main/AskReddit-Dataset/train.csv\")\n",
    "test_data = pd.read_csv(\"C:/Users/saira/Desktop/B-Tech/projects/AskReddit-main/AskReddit-Dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXgeVcTL-c-G"
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hXo6HTHNPF3u",
    "outputId": "4ad23084-a443-45ea-da96-2449570fc2b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a3dee568776c08512c89</td>\n",
       "      <td>What is the role of Lua in Civ4?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bdb84f519e7b46e7b7bb</td>\n",
       "      <td>What are important chapters in Kannada for 10 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29c88db470e2eb5c97ad</td>\n",
       "      <td>Do musicians get royalties from YouTube?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3387d99bf2c3227ae8f1</td>\n",
       "      <td>What is the difference between Scaling Social ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e79fa5038f765d0f2e7e</td>\n",
       "      <td>Why do elevators go super slow right before th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  a3dee568776c08512c89                   What is the role of Lua in Civ4?   \n",
       "1  bdb84f519e7b46e7b7bb  What are important chapters in Kannada for 10 ...   \n",
       "2  29c88db470e2eb5c97ad           Do musicians get royalties from YouTube?   \n",
       "3  3387d99bf2c3227ae8f1  What is the difference between Scaling Social ...   \n",
       "4  e79fa5038f765d0f2e7e  Why do elevators go super slow right before th...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Acij6-9wPM6r",
    "outputId": "3c44780e-1b4e-40e0-b697-1aa8bbd81ac6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 653061 entries, 0 to 653060\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   qid            653061 non-null  object\n",
      " 1   question_text  653061 non-null  object\n",
      " 2   target         653061 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 14.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8j6Eeq5KW1OK",
    "outputId": "08c94a2f-2441-4001-fa79-dddc7f0d77c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653061, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXcmWZxgXBCj",
    "outputId": "3e13c272-f00d-481f-f1ec-c6151966b61f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653061, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl2omaErsGJh",
    "outputId": "e0ba1569-b58b-449d-d0cc-60f5c941a7fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              0\n",
       "question_text    0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2raYP4o6sLsV",
    "outputId": "1a55a5c6-0642-4036-ba18-0aa0a61e5d5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              0\n",
       "question_text    0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data == \"?\").sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cg8Rb97dN7Ns",
    "outputId": "407b4287-47cf-40f5-afa7-e32849b49795"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bG0fHdGmhYoA",
    "outputId": "c91f9532-268a-49f3-b926-38cc6bb4a51c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    612656\n",
       "1     40405\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "WOqkBQRUO2n-",
    "outputId": "dbeae38b-9b52-4a59-d5eb-03bd79103309",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train_data['target']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08dXEn_9Ogqb",
    "outputId": "348b5c71-9c54-4e0e-f1c9-c5f63c47a173"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              0\n",
       "question_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNPwf49hOgqe",
    "outputId": "07bb1d15-43c6-49e6-fa96-c3851e7d72c8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              0\n",
       "question_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_data == \"?\").sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_RjTdmdOtIT",
    "outputId": "bb88d9eb-140f-4391-f149-d598e063a14d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "H0cQWfiuW5f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saira\\AppData\\Local\\Temp\\ipykernel_19412\\3971377198.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  main_data = train_data.append(test_data)\n"
     ]
    }
   ],
   "source": [
    "main_data = train_data.append(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "o6JY21mrdOyw"
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1,4)) \n",
    "final_data = count_vectorizer.fit_transform(main_data['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "IMvUKgqTWpfR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1306122x20650674 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 55138457 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = final_data[:653061,:]\n",
    "final_test_data  = final_data[653061:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "oYtXeP6Gto1q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = train_data['target'].to_numpy()\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2Pg2KKEWdi4A"
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(questions, targets, test_size=0.2, random_state=40, stratify=targets) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7qwn5-7Kfyz"
   },
   "source": [
    "##  Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "asgJSpapKfyz"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.77, class_weight= {0:0.25,1:1}, solver = 'liblinear', max_iter=10000, penalty = 'l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0WnsqQySann7",
    "outputId": "e1740e6e-2bb6-426f-f4bd-e10a82e9cd3b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.77, class_weight={0: 0.25, 1: 1}, max_iter=10000,\n",
       "                   penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.77, class_weight={0: 0.25, 1: 1}, max_iter=10000,\n",
       "                   penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.77, class_weight={0: 0.25, 1: 1}, max_iter=10000,\n",
       "                   penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Dg3XKJ_PKfy0"
   },
   "outputs": [],
   "source": [
    "train_yhat = model.predict(train_X)\n",
    "test_yhat = model.predict(test_X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FI9WZ7GwKfy0",
    "outputId": "62241849-8c6c-4168-982d-b5965fda21c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7001221638093145"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(train_y, train_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cW7IjbSKfy0",
    "outputId": "2df1c729-5ac4-4dfe-efee-98accf646465"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6307546008838172"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(test_y, test_yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKHw9zmmKfy1"
   },
   "source": [
    "##  Final fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VHz8iElnbz7",
    "outputId": "5db3f44c-63b2-4bb4-9b8e-2426dc166dd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.77, class_weight={0: 0.25, 1: 1}, max_iter=10000,\n",
       "                   penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.77, class_weight={0: 0.25, 1: 1}, max_iter=10000,\n",
       "                   penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.77, class_weight={0: 0.25, 1: 1}, max_iter=10000,\n",
       "                   penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(questions, train_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "m49PDWhoKfy1",
    "outputId": "e1fdc83f-5e9c-46ac-b49b-d5d5d9754beb"
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(final_test_data)\n",
    "test_data[\"target\"] = yhat \n",
    "to_submit = test_data[[\"qid\", \"target\"]]\n",
    "to_submit.to_csv(\"project_submission.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "niex0_2dbZST",
    "outputId": "e4d8ce13-73b7-4d9f-a409-e627e5b206b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([603438,  49623], dtype=int64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(yhat,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'what': 19169028,\n",
       " 'is': 9133898,\n",
       " 'the': 16515621,\n",
       " 'role': 14569760,\n",
       " 'of': 12042983,\n",
       " 'lua': 10535676,\n",
       " 'in': 8492555,\n",
       " 'civ4': 3683178,\n",
       " 'what is': 19265970,\n",
       " 'is the': 9424711,\n",
       " 'the role': 17038319,\n",
       " 'role of': 14571979,\n",
       " 'of lua': 12240019,\n",
       " 'lua in': 10535680,\n",
       " 'in civ4': 8545566,\n",
       " 'what is the': 19303607,\n",
       " 'is the role': 9466416,\n",
       " 'the role of': 17038406,\n",
       " 'role of lua': 14572950,\n",
       " 'of lua in': 12240020,\n",
       " 'lua in civ4': 10535681,\n",
       " 'what is the role': 19308581,\n",
       " 'is the role of': 9466430,\n",
       " 'the role of lua': 17038802,\n",
       " 'role of lua in': 14572951,\n",
       " 'of lua in civ4': 12240021,\n",
       " 'are': 1457067,\n",
       " 'important': 8469143,\n",
       " 'chapters': 3527303,\n",
       " 'kannada': 9868017,\n",
       " 'for': 6364346,\n",
       " '10': 6485,\n",
       " 'icse': 8264662,\n",
       " '2018': 106141,\n",
       " 'what are': 19174646,\n",
       " 'are important': 1519373,\n",
       " 'important chapters': 8470127,\n",
       " 'chapters in': 3527503,\n",
       " 'in kannada': 8628773,\n",
       " 'kannada for': 9868151,\n",
       " 'for 10': 6364388,\n",
       " '10 icse': 11058,\n",
       " 'icse 2018': 8264743,\n",
       " 'what are important': 19180426,\n",
       " 'are important chapters': 1519402,\n",
       " 'important chapters in': 8470151,\n",
       " 'chapters in kannada': 3527548,\n",
       " 'in kannada for': 8628782,\n",
       " 'kannada for 10': 9868152,\n",
       " 'for 10 icse': 6364486,\n",
       " '10 icse 2018': 11059,\n",
       " 'what are important chapters': 19180432,\n",
       " 'are important chapters in': 1519406,\n",
       " 'important chapters in kannada': 8470161,\n",
       " 'chapters in kannada for': 3527549,\n",
       " 'in kannada for 10': 8628783,\n",
       " 'kannada for 10 icse': 9868153,\n",
       " 'for 10 icse 2018': 6364487,\n",
       " 'do': 4865240,\n",
       " 'musicians': 11438776,\n",
       " 'get': 6947765,\n",
       " 'royalties': 14605819,\n",
       " 'from': 6708917,\n",
       " 'youtube': 20624201,\n",
       " 'do musicians': 4984719,\n",
       " 'musicians get': 11438931,\n",
       " 'get royalties': 7006454,\n",
       " 'royalties from': 14605854,\n",
       " 'from youtube': 6798701,\n",
       " 'do musicians get': 4984738,\n",
       " 'musicians get royalties': 11438936,\n",
       " 'get royalties from': 7006455,\n",
       " 'royalties from youtube': 14605861,\n",
       " 'do musicians get royalties': 4984740,\n",
       " 'musicians get royalties from': 11438937,\n",
       " 'get royalties from youtube': 7006456,\n",
       " 'difference': 4728566,\n",
       " 'between': 2519011,\n",
       " 'scaling': 14765039,\n",
       " 'social': 15404046,\n",
       " 'enterprises': 5697583,\n",
       " 'and': 897148,\n",
       " 'franchising': 6654223,\n",
       " 'the difference': 16688344,\n",
       " 'difference between': 4728886,\n",
       " 'between scaling': 2554217,\n",
       " 'scaling social': 14765166,\n",
       " 'social enterprises': 15405884,\n",
       " 'enterprises and': 5697589,\n",
       " 'and social': 1158294,\n",
       " 'social franchising': 15406151,\n",
       " 'is the difference': 9440119,\n",
       " 'the difference between': 16688422,\n",
       " 'difference between scaling': 4740385,\n",
       " 'between scaling social': 2554218,\n",
       " 'scaling social enterprises': 14765167,\n",
       " 'social enterprises and': 15405885,\n",
       " 'enterprises and social': 5697591,\n",
       " 'and social franchising': 1158387,\n",
       " 'what is the difference': 19305205,\n",
       " 'is the difference between': 9440133,\n",
       " 'the difference between scaling': 16692493,\n",
       " 'difference between scaling social': 4740386,\n",
       " 'between scaling social enterprises': 2554219,\n",
       " 'scaling social enterprises and': 14765168,\n",
       " 'social enterprises and social': 15405886,\n",
       " 'enterprises and social franchising': 5697592,\n",
       " 'why': 19669864,\n",
       " 'elevators': 5577280,\n",
       " 'go': 7125566,\n",
       " 'super': 16037491,\n",
       " 'slow': 15323755,\n",
       " 'right': 14525802,\n",
       " 'before': 2322739,\n",
       " 'doors': 5324952,\n",
       " 'open': 12727351,\n",
       " 'why do': 19707016,\n",
       " 'do elevators': 4917336,\n",
       " 'elevators go': 5577309,\n",
       " 'go super': 7136217,\n",
       " 'super slow': 16039547,\n",
       " 'slow right': 15324817,\n",
       " 'right before': 14527068,\n",
       " 'before the': 2333857,\n",
       " 'the doors': 16703553,\n",
       " 'doors open': 5325124,\n",
       " 'why do elevators': 19711843,\n",
       " 'do elevators go': 4917341,\n",
       " 'elevators go super': 5577310,\n",
       " 'go super slow': 7136225,\n",
       " 'super slow right': 16039553,\n",
       " 'slow right before': 15324818,\n",
       " 'right before the': 14527140,\n",
       " 'before the doors': 2334254,\n",
       " 'the doors open': 16703577,\n",
       " 'why do elevators go': 19711846,\n",
       " 'do elevators go super': 4917342,\n",
       " 'elevators go super slow': 5577311,\n",
       " 'go super slow right': 7136226,\n",
       " 'super slow right before': 16039554,\n",
       " 'slow right before the': 15324819,\n",
       " 'right before the doors': 14527146,\n",
       " 'before the doors open': 2334255,\n",
       " 'could': 4140112,\n",
       " 'jewish': 9754714,\n",
       " 'mafia': 10575773,\n",
       " 'control': 4070154,\n",
       " 'certain': 3474394,\n",
       " 'scientific': 14810873,\n",
       " 'fields': 6184190,\n",
       " 'like': 10284333,\n",
       " 'cosmology': 4129203,\n",
       " 'theoretical': 17288681,\n",
       " 'physics': 13433896,\n",
       " 'could the': 4160109,\n",
       " 'the jewish': 16831212,\n",
       " 'jewish mafia': 9755775,\n",
       " 'mafia control': 10575844,\n",
       " 'control certain': 4071122,\n",
       " 'certain scientific': 3477070,\n",
       " 'scientific fields': 14811815,\n",
       " 'fields like': 6184738,\n",
       " 'like cosmology': 10295617,\n",
       " 'cosmology and': 4129208,\n",
       " 'and theoretical': 1191430,\n",
       " 'theoretical physics': 17289049,\n",
       " 'could the jewish': 4160687,\n",
       " 'the jewish mafia': 16831334,\n",
       " 'jewish mafia control': 9755776,\n",
       " 'mafia control certain': 10575845,\n",
       " 'control certain scientific': 4071123,\n",
       " 'certain scientific fields': 3477071,\n",
       " 'scientific fields like': 14811818,\n",
       " 'fields like cosmology': 6184747,\n",
       " 'like cosmology and': 10295618,\n",
       " 'cosmology and theoretical': 4129222,\n",
       " 'and theoretical physics': 1191439,\n",
       " 'could the jewish mafia': 4160688,\n",
       " 'the jewish mafia control': 16831335,\n",
       " 'jewish mafia control certain': 9755777,\n",
       " 'mafia control certain scientific': 10575846,\n",
       " 'control certain scientific fields': 4071124,\n",
       " 'certain scientific fields like': 3477072,\n",
       " 'scientific fields like cosmology': 14811819,\n",
       " 'fields like cosmology and': 6184748,\n",
       " 'like cosmology and theoretical': 10295619,\n",
       " 'cosmology and theoretical physics': 4129223,\n",
       " 'disadvantages': 4801209,\n",
       " 'making': 10664356,\n",
       " 'lasagna': 10072761,\n",
       " 'with': 19916319,\n",
       " 'uncooked': 18399773,\n",
       " 'noodles': 11862154,\n",
       " 'are the': 1607319,\n",
       " 'the disadvantages': 16698498,\n",
       " 'disadvantages of': 4801398,\n",
       " 'of making': 12242227,\n",
       " 'making lasagna': 10667801,\n",
       " 'lasagna with': 10072790,\n",
       " 'with uncooked': 20032482,\n",
       " 'uncooked noodles': 18399798,\n",
       " 'what are the': 19189588,\n",
       " 'are the disadvantages': 1617257,\n",
       " 'the disadvantages of': 16698530,\n",
       " 'disadvantages of making': 4802204,\n",
       " 'of making lasagna': 12242461,\n",
       " 'making lasagna with': 10667802,\n",
       " 'lasagna with uncooked': 10072793,\n",
       " 'with uncooked noodles': 20032483,\n",
       " 'what are the disadvantages': 19190770,\n",
       " 'are the disadvantages of': 1617270,\n",
       " 'the disadvantages of making': 16698690,\n",
       " 'disadvantages of making lasagna': 4802206,\n",
       " 'of making lasagna with': 12242462,\n",
       " 'making lasagna with uncooked': 10667803,\n",
       " 'lasagna with uncooked noodles': 10072794,\n",
       " 'all': 618051,\n",
       " 'charges': 3542882,\n",
       " 'were': 19129999,\n",
       " 'withdrawn': 20042601,\n",
       " 'by': 2979579,\n",
       " 'state': 15758365,\n",
       " 'siting': 15279387,\n",
       " 'that': 16372925,\n",
       " 'has': 7488231,\n",
       " 'realised': 14198097,\n",
       " 'this': 17490831,\n",
       " 'an': 799055,\n",
       " 'unwinnable': 18484061,\n",
       " 'case': 3393666,\n",
       " 'can': 3096697,\n",
       " 'it': 9564060,\n",
       " 'be': 2139228,\n",
       " 'reinstated': 14325930,\n",
       " 'all charges': 622293,\n",
       " 'charges were': 3544111,\n",
       " 'were withdrawn': 19156592,\n",
       " 'withdrawn by': 20042617,\n",
       " 'by the': 3029589,\n",
       " 'the state': 17089679,\n",
       " 'state siting': 15765112,\n",
       " 'siting that': 15279394,\n",
       " 'that the': 16484016,\n",
       " 'state has': 15761241,\n",
       " 'has realised': 7522174,\n",
       " 'realised that': 14198171,\n",
       " 'that this': 16494945,\n",
       " 'this is': 17503842,\n",
       " 'is an': 9152827,\n",
       " 'an unwinnable': 882585,\n",
       " 'unwinnable case': 18484062,\n",
       " 'case can': 3394193,\n",
       " 'can it': 3194679,\n",
       " 'it be': 9573489,\n",
       " 'be reinstated': 2209541,\n",
       " 'all charges were': 622304,\n",
       " 'charges were withdrawn': 3544117,\n",
       " 'were withdrawn by': 19156593,\n",
       " 'withdrawn by the': 20042622,\n",
       " 'by the state': 3033809,\n",
       " 'the state siting': 17090261,\n",
       " 'state siting that': 15765113,\n",
       " 'siting that the': 15279395,\n",
       " 'that the state': 16489571,\n",
       " 'the state has': 17089886,\n",
       " 'state has realised': 15761282,\n",
       " 'has realised that': 7522175,\n",
       " 'realised that this': 14198215,\n",
       " 'that this is': 16495052,\n",
       " 'this is an': 17503882,\n",
       " 'is an unwinnable': 9156702,\n",
       " 'an unwinnable case': 882586,\n",
       " 'unwinnable case can': 18484063,\n",
       " 'case can it': 3394212,\n",
       " 'can it be': 3194717,\n",
       " 'it be reinstated': 9575445,\n",
       " 'all charges were withdrawn': 622305,\n",
       " 'charges were withdrawn by': 3544118,\n",
       " 'were withdrawn by the': 19156594,\n",
       " 'withdrawn by the state': 20042623,\n",
       " 'by the state siting': 3033822,\n",
       " 'the state siting that': 17090262,\n",
       " 'state siting that the': 15765114,\n",
       " 'siting that the state': 15279396,\n",
       " 'that the state has': 16489574,\n",
       " 'the state has realised': 17089888,\n",
       " 'state has realised that': 15761283,\n",
       " 'has realised that this': 7522177,\n",
       " 'realised that this is': 14198216,\n",
       " 'that this is an': 16495054,\n",
       " 'this is an unwinnable': 17503906,\n",
       " 'is an unwinnable case': 9156703,\n",
       " 'an unwinnable case can': 882587,\n",
       " 'unwinnable case can it': 18484064,\n",
       " 'case can it be': 3394213,\n",
       " 'can it be reinstated': 3194912,\n",
       " 'was': 18887109,\n",
       " 'supercharger': 16040383,\n",
       " 'mad': 10560316,\n",
       " 'max': 10861890,\n",
       " 'fake': 6030253,\n",
       " 'why was': 19796382,\n",
       " 'was supercharger': 18930850,\n",
       " 'supercharger in': 16040389,\n",
       " 'in mad': 8641749,\n",
       " 'mad max': 10560829,\n",
       " 'max fake': 10862106,\n",
       " 'why was supercharger': 19798848,\n",
       " 'was supercharger in': 18930851,\n",
       " 'supercharger in mad': 16040390,\n",
       " 'in mad max': 8641752,\n",
       " 'mad max fake': 10560837,\n",
       " 'why was supercharger in': 19798849,\n",
       " 'was supercharger in mad': 18930852,\n",
       " 'supercharger in mad max': 16040391,\n",
       " 'in mad max fake': 8641754,\n",
       " 'phone': 13408105,\n",
       " 'hacking': 7387048,\n",
       " 'common': 3864924,\n",
       " 'finland': 6259374,\n",
       " 'is phone': 9362829,\n",
       " 'phone hacking': 13410682,\n",
       " 'hacking common': 7387198,\n",
       " 'common in': 3867814,\n",
       " 'in finland': 8582688,\n",
       " 'is phone hacking': 9362849,\n",
       " 'phone hacking common': 13410683,\n",
       " 'hacking common in': 7387199,\n",
       " 'common in finland': 3867911,\n",
       " 'is phone hacking common': 9362850,\n",
       " 'phone hacking common in': 13410684,\n",
       " 'hacking common in finland': 7387200,\n",
       " 'word': 20109332,\n",
       " 'scent': 14775994,\n",
       " 'which': 19505272,\n",
       " 'more': 11235376,\n",
       " 'knowing': 9986310,\n",
       " 'letter': 10216018,\n",
       " 'silent': 15217799,\n",
       " 'or': 12768177,\n",
       " 'spelling': 15650538,\n",
       " 'context': 4056301,\n",
       " 'used': 18603162,\n",
       " 'in the': 8735902,\n",
       " 'the word': 17184970,\n",
       " 'word scent': 20114483,\n",
       " 'scent which': 14776084,\n",
       " 'which is': 19535289,\n",
       " 'is more': 9326084,\n",
       " 'more important': 11249947,\n",
       " 'important knowing': 8473840,\n",
       " 'knowing which': 9988269,\n",
       " 'which letter': 19542165,\n",
       " 'letter is': 10217128,\n",
       " 'is silent': 9400153,\n",
       " 'silent or': 15218325,\n",
       " 'or the': 12878025,\n",
       " 'the spelling': 17085565,\n",
       " 'spelling and': 15650547,\n",
       " 'and the': 1179008,\n",
       " 'the context': 16658285,\n",
       " 'context it': 4056541,\n",
       " 'it is': 9612400,\n",
       " 'is used': 9507209,\n",
       " 'used in': 18609315,\n",
       " 'in the word': 8763120,\n",
       " 'the word scent': 17186762,\n",
       " 'word scent which': 20114484,\n",
       " 'scent which is': 14776085,\n",
       " 'which is more': 19538004,\n",
       " 'is more important': 9326932,\n",
       " 'more important knowing': 11250162,\n",
       " 'important knowing which': 8473843,\n",
       " 'knowing which letter': 9988272,\n",
       " 'which letter is': 19542166,\n",
       " 'letter is silent': 10217167,\n",
       " 'is silent or': 9400183,\n",
       " 'silent or the': 15218332,\n",
       " 'or the spelling': 12880305,\n",
       " 'the spelling and': 17085570,\n",
       " 'spelling and the': 15650568,\n",
       " 'and the context': 1180606,\n",
       " 'the context it': 16658311,\n",
       " 'context it is': 4056544,\n",
       " 'it is used': 9617491,\n",
       " 'is used in': 9507547,\n",
       " 'in the word scent': 8763142,\n",
       " 'the word scent which': 17186763,\n",
       " 'word scent which is': 20114485,\n",
       " 'scent which is more': 14776086,\n",
       " 'which is more important': 19538086,\n",
       " 'is more important knowing': 9326985,\n",
       " 'more important knowing which': 11250163,\n",
       " 'important knowing which letter': 8473844,\n",
       " 'knowing which letter is': 9988273,\n",
       " 'which letter is silent': 19542170,\n",
       " 'letter is silent or': 10217169,\n",
       " 'is silent or the': 9400184,\n",
       " 'silent or the spelling': 15218334,\n",
       " 'or the spelling and': 12880306,\n",
       " 'the spelling and the': 17085573,\n",
       " 'spelling and the context': 15650569,\n",
       " 'and the context it': 1180607,\n",
       " 'the context it is': 16658312,\n",
       " 'context it is used': 4056545,\n",
       " 'it is used in': 9617498,\n",
       " 'speak': 15620483,\n",
       " 'english': 5669967,\n",
       " 'arabic': 1448461,\n",
       " 'french': 6675648,\n",
       " 'italian': 9680691,\n",
       " 'spanish': 15615771,\n",
       " 'fluently': 6325864,\n",
       " 'want': 18850157,\n",
       " 'to': 17632107,\n",
       " 'learn': 10127236,\n",
       " 'new': 11756416,\n",
       " 'language': 10047363,\n",
       " 'myself': 11602740,\n",
       " 'would': 20190723,\n",
       " 'you': 20343624,\n",
       " 'recommend': 14258761,\n",
       " 'speak english': 15621099,\n",
       " 'english arabic': 5670616,\n",
       " 'arabic french': 1448810,\n",
       " 'french italian': 6677149,\n",
       " 'italian and': 9680778,\n",
       " 'and spanish': 1161860,\n",
       " 'spanish fluently': 15616390,\n",
       " 'fluently and': 6325873,\n",
       " 'and want': 1212127,\n",
       " 'want to': 18856179,\n",
       " 'to learn': 17854523,\n",
       " 'learn new': 10136082,\n",
       " 'new language': 11766083,\n",
       " 'language by': 10048512,\n",
       " 'by myself': 3013095,\n",
       " 'myself what': 11608349,\n",
       " 'what would': 19380902,\n",
       " 'would you': 20240033,\n",
       " 'you recommend': 20478486,\n",
       " 'speak english arabic': 15621123,\n",
       " 'english arabic french': 5670621,\n",
       " 'arabic french italian': 1448815,\n",
       " 'french italian and': 6677150,\n",
       " 'italian and spanish': 9680813,\n",
       " 'and spanish fluently': 1161872,\n",
       " 'spanish fluently and': 15616391,\n",
       " 'fluently and want': 6325887,\n",
       " 'and want to': 1212304,\n",
       " 'want to learn': 18860814,\n",
       " 'to learn new': 17856995,\n",
       " 'learn new language': 10136106,\n",
       " 'new language by': 11766100,\n",
       " 'language by myself': 10048531,\n",
       " 'by myself what': 3013201,\n",
       " 'myself what would': 11608388,\n",
       " 'what would you': 19384141,\n",
       " 'would you recommend': 20244912,\n",
       " 'speak english arabic french': 15621124,\n",
       " 'english arabic french italian': 5670622,\n",
       " 'arabic french italian and': 1448816,\n",
       " 'french italian and spanish': 6677153,\n",
       " 'italian and spanish fluently': 9680814,\n",
       " 'and spanish fluently and': 1161873,\n",
       " 'spanish fluently and want': 15616392,\n",
       " 'fluently and want to': 6325888,\n",
       " 'and want to learn': 1212440,\n",
       " 'want to learn new': 18860922,\n",
       " 'to learn new language': 17857005,\n",
       " 'learn new language by': 10136111,\n",
       " 'new language by myself': 11766101,\n",
       " 'language by myself what': 10048532,\n",
       " 'by myself what would': 3013203,\n",
       " 'myself what would you': 11608389,\n",
       " 'what would you recommend': 19384263,\n",
       " 'relationship': 14338015,\n",
       " 'totti': 18131665,\n",
       " 'buffon': 2869461,\n",
       " 'the relationship': 17025050,\n",
       " 'relationship like': 14341921,\n",
       " 'like between': 10291162,\n",
       " 'between totti': 2562865,\n",
       " 'totti and': 18131666,\n",
       " 'and buffon': 938602,\n",
       " 'is the relationship': 9465464,\n",
       " 'the relationship like': 17025730,\n",
       " 'relationship like between': 14341924,\n",
       " 'like between totti': 10291243,\n",
       " 'between totti and': 2562866,\n",
       " 'totti and buffon': 18131667,\n",
       " 'what is the relationship': 19308421,\n",
       " 'is the relationship like': 9465478,\n",
       " 'the relationship like between': 17025731,\n",
       " 'relationship like between totti': 14341949,\n",
       " 'like between totti and': 10291244,\n",
       " 'between totti and buffon': 2562867,\n",
       " 'if': 8288643,\n",
       " 'stalin': 15706467,\n",
       " 'kept': 9900136,\n",
       " 'tukhachevsky': 18303254,\n",
       " 'alive': 616451,\n",
       " 'how': 7994580,\n",
       " 'good': 7173387,\n",
       " 'general': 6909271,\n",
       " 'he': 7686972,\n",
       " 'have': 7551681,\n",
       " 'been': 2299589,\n",
       " 'during': 5417447,\n",
       " 'operation': 12739445,\n",
       " 'barbarossa': 2097478,\n",
       " 'if stalin': 8367983,\n",
       " 'stalin kept': 15706791,\n",
       " 'kept tukhachevsky': 9901320,\n",
       " 'tukhachevsky alive': 18303255,\n",
       " 'alive how': 616889,\n",
       " 'how good': 8111986,\n",
       " 'good of': 7201473,\n",
       " 'of general': 12174985,\n",
       " 'general would': 6914587,\n",
       " 'would he': 20210133,\n",
       " 'he have': 7698902,\n",
       " 'have been': 7565397,\n",
       " 'been during': 2305509,\n",
       " 'during operation': 5422774,\n",
       " 'operation barbarossa': 12739540,\n",
       " 'if stalin kept': 8367995,\n",
       " 'stalin kept tukhachevsky': 15706792,\n",
       " 'kept tukhachevsky alive': 9901321,\n",
       " 'tukhachevsky alive how': 18303256,\n",
       " 'alive how good': 616897,\n",
       " 'how good of': 8112961,\n",
       " 'good of general': 7201499,\n",
       " 'of general would': 12175130,\n",
       " 'general would he': 6914590,\n",
       " 'would he have': 20210362,\n",
       " 'he have been': 7698946,\n",
       " 'have been during': 7566316,\n",
       " 'been during operation': 2305510,\n",
       " 'during operation barbarossa': 5422778,\n",
       " 'if stalin kept tukhachevsky': 8367996,\n",
       " 'stalin kept tukhachevsky alive': 15706793,\n",
       " 'kept tukhachevsky alive how': 9901322,\n",
       " 'tukhachevsky alive how good': 18303257,\n",
       " 'alive how good of': 616898,\n",
       " 'how good of general': 8112968,\n",
       " 'good of general would': 7201500,\n",
       " 'of general would he': 12175131,\n",
       " 'general would he have': 6914591,\n",
       " 'would he have been': 20210372,\n",
       " 'he have been during': 7698952,\n",
       " 'have been during operation': 7566317,\n",
       " 'been during operation barbarossa': 2305511,\n",
       " 'some': 15453827,\n",
       " 'workout': 20152764,\n",
       " 'shoes': 15085569,\n",
       " 'cheap': 3552899,\n",
       " 'are some': 1581365,\n",
       " 'some good': 15474089,\n",
       " 'good workout': 7217495,\n",
       " 'workout shoes': 20153532,\n",
       " 'shoes for': 15085889,\n",
       " 'for cheap': 6401474,\n",
       " 'what are some': 19185552,\n",
       " 'are some good': 1587248,\n",
       " 'some good workout': 15478189,\n",
       " 'good workout shoes': 7217519,\n",
       " 'workout shoes for': 20153533,\n",
       " 'shoes for cheap': 15085897,\n",
       " 'what are some good': 19186749,\n",
       " 'are some good workout': 1588625,\n",
       " 'some good workout shoes': 15478192,\n",
       " 'good workout shoes for': 7217520,\n",
       " 'workout shoes for cheap': 20153534,\n",
       " 'sentence': 14957010,\n",
       " 'correct': 4117536,\n",
       " 'proper': 13886361,\n",
       " 'she': 15049552,\n",
       " 'understand': 18416182,\n",
       " 'nothing': 11949407,\n",
       " 'is this': 9490423,\n",
       " 'this sentence': 17514641,\n",
       " 'sentence correct': 14957271,\n",
       " 'correct and': 4117664,\n",
       " 'and proper': 1125180,\n",
       " 'proper she': 13887581,\n",
       " 'she could': 15051839,\n",
       " 'could understand': 4162487,\n",
       " 'understand nothing': 18418779,\n",
       " 'is this sentence': 9493088,\n",
       " 'this sentence correct': 17514660,\n",
       " 'sentence correct and': 14957274,\n",
       " 'correct and proper': 4117716,\n",
       " 'and proper she': 1125201,\n",
       " 'proper she could': 13887582,\n",
       " 'she could understand': 15051906,\n",
       " 'could understand nothing': 4162499,\n",
       " 'is this sentence correct': 9493091,\n",
       " 'this sentence correct and': 17514661,\n",
       " 'sentence correct and proper': 14957276,\n",
       " 'correct and proper she': 4117717,\n",
       " 'and proper she could': 1125202,\n",
       " 'proper she could understand': 13887583,\n",
       " 'she could understand nothing': 15051907,\n",
       " 'stupid': 15955053,\n",
       " 'things': 17436583,\n",
       " 'indians': 8880205,\n",
       " 'when': 19394364,\n",
       " 'your': 20543451,\n",
       " 'country': 4183591,\n",
       " 'what stupid': 19355706,\n",
       " 'stupid things': 15957192,\n",
       " 'things do': 17439283,\n",
       " 'do indians': 4956370,\n",
       " 'indians do': 8882078,\n",
       " 'do when': 5076357,\n",
       " 'when in': 19420307,\n",
       " 'in your': 8796163,\n",
       " 'your country': 20556851,\n",
       " 'what stupid things': 19355711,\n",
       " 'stupid things do': 15957207,\n",
       " 'things do indians': 17439314,\n",
       " 'do indians do': 4956517,\n",
       " 'indians do when': 8882130,\n",
       " 'do when in': 5076974,\n",
       " 'when in your': 19420705,\n",
       " 'in your country': 8796800,\n",
       " 'what stupid things do': 19355712,\n",
       " 'stupid things do indians': 15957208,\n",
       " 'things do indians do': 17439315,\n",
       " 'do indians do when': 4956521,\n",
       " 'indians do when in': 8882131,\n",
       " 'do when in your': 5076980,\n",
       " 'when in your country': 19420709,\n",
       " 'where': 19473755,\n",
       " 'market': 10778594,\n",
       " 'research': 14434554,\n",
       " 'report': 14405791,\n",
       " 'on': 12530425,\n",
       " 'global': 7115841,\n",
       " 'textile': 16333959,\n",
       " 'dyes': 5435021,\n",
       " 'where can': 19475792,\n",
       " 'can get': 3169048,\n",
       " 'get the': 7013440,\n",
       " 'the market': 16872219,\n",
       " 'market research': 10782512,\n",
       " 'research report': 14438506,\n",
       " 'report on': 14407130,\n",
       " 'on the': 12608431,\n",
       " 'the global': 16773198,\n",
       " 'global textile': 7118244,\n",
       " 'textile dyes': 16334050,\n",
       " 'dyes market': 5435045,\n",
       " 'where can get': 19478713,\n",
       " 'can get the': 3177822,\n",
       " 'get the market': 7015116,\n",
       " 'the market research': 16872557,\n",
       " 'market research report': 10782578,\n",
       " 'research report on': 14438515,\n",
       " 'report on the': 14407220,\n",
       " 'on the global': 12612278,\n",
       " 'the global textile': 16773620,\n",
       " 'global textile dyes': 7118245,\n",
       " 'textile dyes market': 16334051,\n",
       " 'where can get the': 19479565,\n",
       " 'can get the market': 3178009,\n",
       " 'get the market research': 7015118,\n",
       " 'the market research report': 16872561,\n",
       " 'market research report on': 10782580,\n",
       " 'research report on the': 14438522,\n",
       " 'report on the global': 14407230,\n",
       " 'on the global textile': 12612329,\n",
       " 'the global textile dyes': 16773621,\n",
       " 'global textile dyes market': 7118246,\n",
       " 'standards': 15714835,\n",
       " 'issued': 9559814,\n",
       " 'because': 2255480,\n",
       " 'convergence': 4080810,\n",
       " 'project': 13866937,\n",
       " 'differences': 4745985,\n",
       " 'gaap': 6852195,\n",
       " 'ifrs': 8407076,\n",
       " 'eliminated': 5580412,\n",
       " 'converged': 4080804,\n",
       " 'topics': 18118426,\n",
       " 'what standards': 19354308,\n",
       " 'standards have': 15715215,\n",
       " 'been issued': 2309579,\n",
       " 'issued because': 9559857,\n",
       " 'because of': 2261065,\n",
       " 'of the': 12367573,\n",
       " 'the convergence': 16659438,\n",
       " 'convergence project': 4080877,\n",
       " 'project have': 13868081,\n",
       " 'have all': 7555309,\n",
       " 'all the': 643705,\n",
       " 'the differences': 16694040,\n",
       " 'differences between': 4746175,\n",
       " 'between gaap': 2535383,\n",
       " 'gaap and': 6852196,\n",
       " 'and ifrs': 1034084,\n",
       " 'ifrs been': 8407089,\n",
       " 'been eliminated': 2305669,\n",
       " 'eliminated for': 5580453,\n",
       " 'for the': 6550814,\n",
       " 'the converged': 16659436,\n",
       " 'converged topics': 4080809,\n",
       " 'what standards have': 19354313,\n",
       " 'standards have been': 15715216,\n",
       " 'have been issued': 7567005,\n",
       " 'been issued because': 2309580,\n",
       " 'issued because of': 9559858,\n",
       " 'because of the': 2263020,\n",
       " 'of the convergence': 12376091,\n",
       " 'the convergence project': 16659450,\n",
       " 'convergence project have': 4080878,\n",
       " 'project have all': 13868082,\n",
       " 'have all the': 7555443,\n",
       " 'all the differences': 645052,\n",
       " 'the differences between': 16694071,\n",
       " 'differences between gaap': 4747069,\n",
       " 'between gaap and': 2535384,\n",
       " 'gaap and ifrs': 6852199,\n",
       " 'and ifrs been': 1034085,\n",
       " 'ifrs been eliminated': 8407090,\n",
       " 'been eliminated for': 2305670,\n",
       " 'eliminated for the': 5580455,\n",
       " 'for the converged': 6553113,\n",
       " 'the converged topics': 16659437,\n",
       " 'what standards have been': 19354314,\n",
       " 'standards have been issued': 15715217,\n",
       " 'have been issued because': 7567006,\n",
       " 'been issued because of': 2309581,\n",
       " 'issued because of the': 9559859,\n",
       " 'because of the convergence': 2263091,\n",
       " 'of the convergence project': 12376092,\n",
       " 'the convergence project have': 16659451,\n",
       " 'convergence project have all': 4080879,\n",
       " 'project have all the': 13868083,\n",
       " 'have all the differences': 7555457,\n",
       " 'all the differences between': 645054,\n",
       " 'the differences between gaap': 16694315,\n",
       " 'differences between gaap and': 4747070,\n",
       " 'between gaap and ifrs': 2535385,\n",
       " 'gaap and ifrs been': 6852200,\n",
       " 'and ifrs been eliminated': 1034086,\n",
       " 'ifrs been eliminated for': 8407091,\n",
       " 'been eliminated for the': 2305671,\n",
       " 'eliminated for the converged': 5580456,\n",
       " 'for the converged topics': 6553114,\n",
       " 'consider': 4005954,\n",
       " 'ideal': 8272161,\n",
       " 'ratio': 14144583,\n",
       " 'time': 17585713,\n",
       " 'spent': 15655187,\n",
       " 'reading': 14182206,\n",
       " 'watching': 18961916,\n",
       " 'tv': 18322319,\n",
       " 'you consider': 20375634,\n",
       " 'consider an': 4006122,\n",
       " 'an ideal': 847208,\n",
       " 'ideal ratio': 8273443,\n",
       " 'ratio of': 14145138,\n",
       " 'of time': 12416991,\n",
       " 'time spent': 17603856,\n",
       " 'spent reading': 15655827,\n",
       " 'reading to': 14185470,\n",
       " 'to time': 18030883,\n",
       " 'spent watching': 15655977,\n",
       " 'watching tv': 18963846,\n",
       " 'would you consider': 20241239,\n",
       " 'you consider an': 20375666,\n",
       " 'consider an ideal': 4006147,\n",
       " 'an ideal ratio': 847418,\n",
       " 'ideal ratio of': 8273444,\n",
       " 'ratio of time': 14145589,\n",
       " 'of time spent': 12417636,\n",
       " 'time spent reading': 17603888,\n",
       " 'spent reading to': 15655830,\n",
       " 'reading to time': 14185498,\n",
       " 'to time spent': 18030968,\n",
       " 'time spent watching': 17603897,\n",
       " 'spent watching tv': 15655978,\n",
       " 'what would you consider': 19384173,\n",
       " 'would you consider an': 20241249,\n",
       " 'you consider an ideal': 20375672,\n",
       " 'consider an ideal ratio': 4006148,\n",
       " 'an ideal ratio of': 847419,\n",
       " 'ideal ratio of time': 8273445,\n",
       " 'ratio of time spent': 14145592,\n",
       " 'of time spent reading': 12417639,\n",
       " 'time spent reading to': 17603890,\n",
       " 'spent reading to time': 15655831,\n",
       " 'reading to time spent': 14185499,\n",
       " 'to time spent watching': 18030969,\n",
       " 'time spent watching tv': 17603898,\n",
       " 'sarcastic': 14715651,\n",
       " 'thanksgiving': 16371737,\n",
       " 'sayings': 14754386,\n",
       " 'some sarcastic': 15505435,\n",
       " 'sarcastic thanksgiving': 14715811,\n",
       " 'thanksgiving sayings': 16371821,\n",
       " 'are some sarcastic': 1595974,\n",
       " 'some sarcastic thanksgiving': 15505444,\n",
       " 'sarcastic thanksgiving sayings': 14715812,\n",
       " 'what are some sarcastic': 19188073,\n",
       " 'are some sarcastic thanksgiving': 1595979,\n",
       " 'some sarcastic thanksgiving sayings': 15505445,\n",
       " 'best': 2421778,\n",
       " 'site': 15272668,\n",
       " 'games': 6868547,\n",
       " 'the best': 16568918,\n",
       " 'best site': 2477684,\n",
       " 'site for': 15273394,\n",
       " 'for games': 6439066,\n",
       " 'is the best': 9428674,\n",
       " 'the best site': 16590746,\n",
       " 'best site for': 2477703,\n",
       " 'site for games': 15273565,\n",
       " 'what is the best': 19304187,\n",
       " 'is the best site': 9432089,\n",
       " 'the best site for': 16590754,\n",
       " 'best site for games': 2477737,\n",
       " 'trump': 18262669,\n",
       " 'merkel': 11032616,\n",
       " 'constantly': 4029175,\n",
       " 'form': 6612733,\n",
       " 'unnatural': 18470710,\n",
       " 'triangle': 18229679,\n",
       " 'shape': 15034922,\n",
       " 'their': 17202593,\n",
       " 'hands': 7434589,\n",
       " 'together': 18077587,\n",
       " 'do trump': 5063950,\n",
       " 'trump and': 18263744,\n",
       " 'and merkel': 1075911,\n",
       " 'merkel constantly': 11032678,\n",
       " 'constantly form': 4030119,\n",
       " 'form an': 6613042,\n",
       " 'an unnatural': 881816,\n",
       " 'unnatural triangle': 18470799,\n",
       " 'triangle shape': 18230177,\n",
       " 'shape with': 15036113,\n",
       " 'with their': 20026148,\n",
       " 'their hands': 17221081,\n",
       " 'hands together': 7435893,\n",
       " 'why do trump': 19726543,\n",
       " 'do trump and': 5063955,\n",
       " 'trump and merkel': 18264067,\n",
       " 'and merkel constantly': 1075912,\n",
       " 'merkel constantly form': 11032679,\n",
       " 'constantly form an': 4030120,\n",
       " 'form an unnatural': 6613098,\n",
       " 'an unnatural triangle': 881821,\n",
       " 'unnatural triangle shape': 18470800,\n",
       " 'triangle shape with': 18230178,\n",
       " 'shape with their': 15036126,\n",
       " 'with their hands': 20026794,\n",
       " 'their hands together': 17221159,\n",
       " 'why do trump and': 19726544,\n",
       " 'do trump and merkel': 5063957,\n",
       " 'trump and merkel constantly': 18264068,\n",
       " 'and merkel constantly form': 1075913,\n",
       " 'merkel constantly form an': 11032680,\n",
       " 'constantly form an unnatural': 4030121,\n",
       " 'form an unnatural triangle': 6613099,\n",
       " 'an unnatural triangle shape': 881822,\n",
       " 'unnatural triangle shape with': 18470801,\n",
       " 'triangle shape with their': 18230179,\n",
       " 'shape with their hands': 15036127,\n",
       " 'with their hands together': 20026803,\n",
       " 'sep': 14961566,\n",
       " 'intake': 8992502,\n",
       " 'yr': 20628890,\n",
       " 'full': 6811901,\n",
       " 'mba': 10873095,\n",
       " 'canada': 3311620,\n",
       " 'us': 18534275,\n",
       " 'exp': 5920005,\n",
       " 'after': 495002,\n",
       " 'till': 17583678,\n",
       " 'date': 4403163,\n",
       " 'as': 1729094,\n",
       " 'ast': 1855556,\n",
       " 'marketing': 10784448,\n",
       " 'manager': 10705834,\n",
       " 'univ': 18448145,\n",
       " 'apply': 1421374,\n",
       " 'for sep': 6532624,\n",
       " 'sep 2018': 14961582,\n",
       " '2018 intake': 108917,\n",
       " 'intake yr': 8992914,\n",
       " 'yr full': 20629016,\n",
       " 'full time': 6816847,\n",
       " 'time mba': 17598758,\n",
       " 'mba in': 10875300,\n",
       " 'in canada': 8536110,\n",
       " 'canada us': 3316274,\n",
       " 'us with': 18556870,\n",
       " 'with yr': 20041126,\n",
       " 'yr of': 20629100,\n",
       " 'of exp': 12158819,\n",
       " 'exp after': 5920011,\n",
       " 'after 10': 495014,\n",
       " '10 till': 14988,\n",
       " 'till date': 17583894,\n",
       " 'date as': 4403721,\n",
       " 'as ast': 1735792,\n",
       " 'ast marketing': 1855565,\n",
       " 'marketing manager': 10786782,\n",
       " 'manager which': 10707783,\n",
       " 'which univ': 19566290,\n",
       " 'univ can': 18448159,\n",
       " 'can apply': 3106560,\n",
       " 'apply for': 1422151,\n",
       " 'for sep 2018': 6532626,\n",
       " 'sep 2018 intake': 14961583,\n",
       " '2018 intake yr': 108925,\n",
       " 'intake yr full': 8992915,\n",
       " 'yr full time': 20629017,\n",
       " 'full time mba': 6817157,\n",
       " 'time mba in': 17598784,\n",
       " 'mba in canada': 10875382,\n",
       " 'in canada us': 8537067,\n",
       " 'canada us with': 3316286,\n",
       " 'us with yr': 18557048,\n",
       " 'with yr of': 20041131,\n",
       " 'yr of exp': 20629105,\n",
       " 'of exp after': 12158820,\n",
       " 'exp after 10': 5920012,\n",
       " 'after 10 till': 495111,\n",
       " '10 till date': 14989,\n",
       " 'till date as': 17583899,\n",
       " 'date as ast': 4403724,\n",
       " 'as ast marketing': 1735793,\n",
       " 'ast marketing manager': 1855566,\n",
       " 'marketing manager which': 10786815,\n",
       " 'manager which univ': 10707790,\n",
       " 'which univ can': 19566291,\n",
       " 'univ can apply': 18448160,\n",
       " 'can apply for': 3106710,\n",
       " 'for sep 2018 intake': 6532627,\n",
       " 'sep 2018 intake yr': 14961584,\n",
       " '2018 intake yr full': 108926,\n",
       " 'intake yr full time': 8992916,\n",
       " 'yr full time mba': 20629018,\n",
       " 'full time mba in': 6817166,\n",
       " 'time mba in canada': 17598787,\n",
       " 'mba in canada us': 10875388,\n",
       " 'in canada us with': 8537071,\n",
       " 'canada us with yr': 3316287,\n",
       " 'us with yr of': 18557049,\n",
       " 'with yr of exp': 20041132,\n",
       " 'yr of exp after': 20629106,\n",
       " 'of exp after 10': 12158821,\n",
       " 'exp after 10 till': 5920013,\n",
       " 'after 10 till date': 495112,\n",
       " '10 till date as': 14990,\n",
       " 'till date as ast': 17583900,\n",
       " 'date as ast marketing': 4403725,\n",
       " 'as ast marketing manager': 1735794,\n",
       " 'ast marketing manager which': 1855567,\n",
       " 'marketing manager which univ': 10786816,\n",
       " 'manager which univ can': 10707791,\n",
       " 'which univ can apply': 19566292,\n",
       " 'univ can apply for': 18448161,\n",
       " 'foundation': 6639469,\n",
       " 'build': 2870605,\n",
       " 'up': 18484461,\n",
       " 'the foundation': 16757599,\n",
       " 'foundation of': 6639956,\n",
       " 'of which': 12442396,\n",
       " 'which to': 19564475,\n",
       " 'to build': 17692774,\n",
       " 'build up': 2876217,\n",
       " 'up the': 18502865,\n",
       " 'the us': 17150376,\n",
       " 'is the foundation': 9444834,\n",
       " 'the foundation of': 16757627,\n",
       " 'foundation of which': 6640049,\n",
       " 'of which to': 12442639,\n",
       " 'which to build': 19564488,\n",
       " 'to build up': 17694475,\n",
       " 'build up the': 2876363,\n",
       " 'up the us': 18503760,\n",
       " 'what is the foundation': 19305887,\n",
       " 'is the foundation of': 9444836,\n",
       " 'the foundation of which': 16757659,\n",
       " 'foundation of which to': 6640050,\n",
       " 'of which to build': 12442640,\n",
       " 'which to build up': 19564489,\n",
       " 'to build up the': 17694497,\n",
       " 'build up the us': 2876369,\n",
       " 'who': 19603633,\n",
       " 'had': 7388377,\n",
       " 'worst': 20180476,\n",
       " 'weapons': 19071363,\n",
       " 'ww1': 20282554,\n",
       " 'ww2': 20282849,\n",
       " ...}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = count_vectorizer.vocabulary_\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer1 = CountVectorizer(ngram_range=(1,4), vocabulary=vocab) \n",
    "dynamic_data = count_vectorizer1.fit_transform([\"you are an atheist and blaming god after back breakage?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_hat = model.predict(dynamic_data)\n",
    "d_hat"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Best.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
